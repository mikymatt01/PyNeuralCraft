{'learning_rate': 0.08, 'momentum': 0.8, 'Nesterov': True, 'kernel_regularizer': 0, 'bias_regularizer': 0, 'weights_initializer': 'xavier_init', 'layers': [{'units': 2, 'inputs': 17, 'act_func': 'relu'}, {'units': 1, 'inputs': 2, 'act_func': 'sigmoid'}], 'name': 'model3', 'epochs': 400, 'loss': 'mean_squared_error', 'metrics': ['accuracy']}
--------------- Layer ---------------
--------------- Perceptron ---------------
---------------  Weights   ---------------
[-10.66408704   2.90973117  12.29042561   3.95273659   2.06368208
  -0.78146672  -2.39203496   6.66107624   5.23237764   3.62985214
  -5.40590724  -7.40039432   7.50117604   3.29178536   0.97897878
  -5.12044231   9.13140447]
---------------    Bias    ---------------
[4.31167327]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 4.47690889 -3.21848192 -1.33011191  5.97505676 -3.51338479 -2.94166325
  5.38776754 -4.52722152  6.85947751 -3.20435965 -3.4456716   6.16719799
 -2.31544451 -2.64000785 -1.18708614  4.99576019 -4.61957296]
---------------    Bias    ---------------
[0.20333959]


--------------- Layer ---------------
--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.26987154 -0.81066963]
---------------    Bias    ---------------
[1.76543601]



