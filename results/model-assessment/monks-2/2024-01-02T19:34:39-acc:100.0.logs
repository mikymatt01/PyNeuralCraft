{'learning_rate': 0.08, 'momentum': 0.8, 'Nesterov': True, 'kernel_regularizer': 0, 'bias_regularizer': 0, 'weights_initializer': 'xavier_init', 'layers': [{'units': 4, 'inputs': 17, 'act_func': 'relu'}, {'units': 1, 'inputs': 4, 'act_func': 'sigmoid'}], 'name': 'model3', 'epochs': 400, 'loss': 'mean_squared_error', 'metrics': ['accuracy']}
--------------- Layer ---------------
--------------- Perceptron ---------------
---------------  Weights   ---------------
[2.90221394 4.09823611 3.6476788  2.05945854 4.8665763  3.46720361
 5.26721827 4.8061119  3.74146313 3.77981343 3.64596651 1.44944072
 2.33564962 4.26681831 2.69777535 4.48268325 5.21447225]
---------------    Bias    ---------------
[9.73957772]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.63753006 -0.41331039  1.05894922  0.28591486  1.20043259 -0.41823642
  3.05879611 -2.31594814 -1.6242183   1.33841699  1.00964408 -2.15337226
  2.67300315  0.62218423 -0.05411324 -0.06588733  0.89814537]
---------------    Bias    ---------------
[0.93049925]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-10.78616296   5.50669233   5.37570532  -9.56033912   6.2598915
   5.1231725   -6.96930621   8.0636858  -11.08272742   6.28519244
   5.36137109 -11.69653161   4.23501962   5.13295555   4.03836993
  -8.57306327   9.17594936]
---------------    Bias    ---------------
[0.60535073]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[16.78047772 -5.92937692 -5.20883185 14.41241181 -4.4625724  -5.08324674
 15.18042179 -9.84021797 15.1898992  -5.48272497 -5.56536229 15.70068545
 -3.72669532 -4.38099795 -2.9691338  13.24165856 -7.43081904]
---------------    Bias    ---------------
[4.70333603]


--------------- Layer ---------------
--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 1.26152111  1.10404818 -2.52567789 -1.72054031]
---------------    Bias    ---------------
[1.80929325]



