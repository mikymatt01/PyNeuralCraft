{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Monk 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "from utils import get_splits\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def retrieveData(data_str):\n",
    "    # Create a DataFrame from the structured data\n",
    "    column_names = [\"R\", \"col2\", \"col3\", \"col4\", \"col5\", \"col6\", \"col7\", \"data\"]\n",
    "    data = pd.read_csv(StringIO(data_str), sep=' ', header=None, names=column_names)\n",
    "    data = data.iloc[:, :-1]\n",
    "    data=data.iloc[np.random.permutation(len(data))]\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    df_scaled = scaler.fit_transform(data.to_numpy())\n",
    "    df_scaled = pd.DataFrame(df_scaled, columns=data.columns.values)\n",
    "    del df_scaled['R']\n",
    "    #del df_scaled['Id']\n",
    "    df_scaled = df_scaled.assign(R=data['R'].values)\n",
    "    df_train = df_scaled\n",
    "    features = 6\n",
    "    X_train = df_train.iloc[ : , :features].values\n",
    "    y_train = df_train.iloc[:,features:].values\n",
    "    return X_train, y_train\n",
    "\n",
    "filename    = \"monk/monks-1\"\n",
    "train       = \".train\"\n",
    "test        = \".test\"\n",
    "\n",
    "f = open(filename + train, 'r')\n",
    "res = f.readlines()\n",
    "f.close()\n",
    "train_str = ''.join(res)\n",
    "X_train, y_train = retrieveData(train_str)\n",
    "\n",
    "f = open(filename + test, 'r')\n",
    "res = f.readlines()\n",
    "f.close()\n",
    "test_str = ''.join(res)\n",
    "X_test, y_test = retrieveData(test_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from activation_function import Tanh, Linear, ReLU, Sigmoid\n",
    "from layer import Layer\n",
    "from mlp import MLP\n",
    "from metrics import Metrics\n",
    "from losses import MeanSquaredError\n",
    "from grid_search import GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = GridSearch()\n",
    "t.read_json([\"models/model1.json\", \"models/model2.json\", \"models/model3.json\"])\n",
    "t.set_dataset(X_train, y_train)\n",
    "t.test_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Layer(\n",
    "        n_perceptrons=8,\n",
    "        n_inputs=len(X_train[0]),\n",
    "        act_func=ReLU(),\n",
    "        #kernel_regularizer=0.0001,\n",
    "        #bias_regularizer=0.01,\n",
    "        momentum=0.9,\n",
    "        Nesterov=True\n",
    "    ),\n",
    "    Layer(\n",
    "        n_perceptrons=len(y_train[0]),\n",
    "        n_inputs=8,\n",
    "        act_func=Sigmoid(),\n",
    "        #kernel_regularizer=0.0001,\n",
    "        #bias_regularizer=0.01,\n",
    "        momentum=0.9,\n",
    "        Nesterov=True\n",
    "    )\n",
    "]\n",
    "\n",
    "model = MLP(layers)\n",
    "\n",
    "epochs, lr = 100, 0.03\n",
    "loss = MeanSquaredError()\n",
    "\n",
    "model.compile(lr,loss, metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, epochs=epochs)\n",
    "model.summary()\n",
    "model.plot_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = Metrics()\n",
    "error = 0  \n",
    "for i in range(len(X_train)):\n",
    "    out = model.run(X_train[i])\n",
    "    print(f'case {i}: {round(out[0], 2)}, {y_train[i][0]}')\n",
    "    track.compute__results(round(out[0]), y_train[i][0])\n",
    "print(\"accuracy: \", track.accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = Metrics()\n",
    "error = 0  \n",
    "for i in range(len(X_test)):\n",
    "    out = model.run(X_test[i])\n",
    "    print(f'case {i}: {round(out[0], 2)}, {y_test[i][0]}')\n",
    "    track.compute__results(round(out[0]), y_test[i][0])\n",
    "print(\"accuracy: \", track.accuracy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
